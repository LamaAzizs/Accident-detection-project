{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyONBrzI97rwydOpYa8IIcr0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LamaAzizs/Accident-detection-project/blob/main/automated_dataset_annotation_and_evaluation_with_grounding_dino_and_sam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMoN223DQr7V",
        "outputId": "1171c845-f04d-440a-b0d3-b3872f9fdeb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(\"HOME:\", HOME)"
      ],
      "metadata": {
        "id": "QPMwXXwzQwuN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {HOME}\n",
        "!git clone https://github.com/IDEA-Research/GroundingDINO.git\n",
        "%cd {HOME}/GroundingDINO\n",
        "!git checkout -q 57535c5a79791cb76e36fdb64975271354f10251\n",
        "!pip install -q -e ."
      ],
      "metadata": {
        "id": "iYVQRnVcQ2wp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {HOME}\n",
        "\n",
        "import sys\n",
        "!{sys.executable} -m pip install 'git+https://github.com/facebookresearch/segment-anything.git'"
      ],
      "metadata": {
        "id": "DCzlfiOxQ6IQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y supervision\n",
        "!pip install -q supervision==0.6.0\n",
        "\n",
        "import supervision as sv\n",
        "print(sv.__version__)"
      ],
      "metadata": {
        "id": "V1rwHYvhQ6vj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y supervision\n",
        "!pip install supervision==0.4.0"
      ],
      "metadata": {
        "id": "3KYVgBufQ-H-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q roboflow"
      ],
      "metadata": {
        "id": "2lWBHNcvRAg2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "GROUNDING_DINO_CONFIG_PATH = os.path.join(HOME, \"GroundingDINO/groundingdino/config/GroundingDINO_SwinT_OGC.py\")\n",
        "print(GROUNDING_DINO_CONFIG_PATH, \"; exist:\", os.path.isfile(GROUNDING_DINO_CONFIG_PATH))"
      ],
      "metadata": {
        "id": "gXdKMSaIRDbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {HOME}\n",
        "!mkdir -p {HOME}/weights\n",
        "%cd {HOME}/weights\n",
        "\n",
        "!wget -q https://github.com/IDEA-Research/GroundingDINO/releases/download/v0.1.0-alpha/groundingdino_swint_ogc.pth"
      ],
      "metadata": {
        "id": "ERzOz9aoRFtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "GROUNDING_DINO_CHECKPOINT_PATH = os.path.join(HOME, \"weights\", \"groundingdino_swint_ogc.pth\")\n",
        "print(GROUNDING_DINO_CHECKPOINT_PATH, \"; exist:\", os.path.isfile(GROUNDING_DINO_CHECKPOINT_PATH))"
      ],
      "metadata": {
        "id": "Kd_mT9ULRH-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {HOME}\n",
        "!mkdir -p {HOME}/weights\n",
        "%cd {HOME}/weights\n",
        "\n",
        "!wget -q https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth"
      ],
      "metadata": {
        "id": "pI1gTFfxRKeW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "SAM_CHECKPOINT_PATH = os.path.join(HOME, \"weights\", \"sam_vit_h_4b8939.pth\")\n",
        "print(SAM_CHECKPOINT_PATH, \"; exist:\", os.path.isfile(SAM_CHECKPOINT_PATH))"
      ],
      "metadata": {
        "id": "L5KslMsQRRAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "R8qQWQuERT5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {HOME}/GroundingDINO\n",
        "\n",
        "from groundingdino.util.inference import Model\n",
        "\n",
        "grounding_dino_model = Model(model_config_path=GROUNDING_DINO_CONFIG_PATH, model_checkpoint_path=GROUNDING_DINO_CHECKPOINT_PATH)"
      ],
      "metadata": {
        "id": "TxFAtJ29RWl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SAM_ENCODER_VERSION = \"vit_h\"\n"
      ],
      "metadata": {
        "id": "wf54Fd3hRZG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from segment_anything import sam_model_registry, SamPredictor\n",
        "\n",
        "sam = sam_model_registry[SAM_ENCODER_VERSION](checkpoint=SAM_CHECKPOINT_PATH).to(device=DEVICE)\n",
        "sam_predictor = SamPredictor(sam)"
      ],
      "metadata": {
        "id": "n7Flyhu2RcY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "\n",
        "def enhance_class_name(class_names: List[str]) -> List[str]:\n",
        "    return [\n",
        "        f\"all {class_name}s\"\n",
        "        for class_name\n",
        "        in class_names\n",
        "    ]"
      ],
      "metadata": {
        "id": "84JRcizaRemF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from segment_anything import SamPredictor\n",
        "\n",
        "\n",
        "def segment(sam_predictor: SamPredictor, image: np.ndarray, xyxy: np.ndarray) -> np.ndarray:\n",
        "    sam_predictor.set_image(image)\n",
        "    result_masks = []\n",
        "    for box in xyxy:\n",
        "        masks, scores, logits = sam_predictor.predict(\n",
        "            box=box,\n",
        "            multimask_output=True\n",
        "        )\n",
        "        index = np.argmax(scores)\n",
        "        result_masks.append(masks[index])\n",
        "    return np.array(result_masks)"
      ],
      "metadata": {
        "id": "rLzEGnRbRppa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "IMAGES_DIRECTORY = os.path.join(HOME, 'data')\n",
        "IMAGES_EXTENSIONS = ['jpg', 'jpeg', 'png']\n",
        "\n",
        "CLASSES = ['Accident', 'Vehicle']\n",
        "\n",
        "BOX_TRESHOLD = 0.35\n",
        "TEXT_TRESHOLD = 0.25"
      ],
      "metadata": {
        "id": "gfcBt_USRste"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "images = {}\n",
        "annotations = {}\n",
        "\n",
        "image_paths = sv.list_files_with_extensions(\n",
        "    directory=IMAGES_DIRECTORY,\n",
        "    extensions=IMAGES_EXTENSIONS)\n",
        "\n",
        "for image_path in tqdm(image_paths):\n",
        "    image_name = image_path.name\n",
        "    image_path = str(image_path)\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    detections = grounding_dino_model.predict_with_classes(\n",
        "        image=image,\n",
        "        classes=enhance_class_name(class_names=CLASSES),\n",
        "        box_threshold=BOX_TRESHOLD,\n",
        "        text_threshold=TEXT_TRESHOLD\n",
        "    )\n",
        "    detections = detections[detections.class_id != None]\n",
        "    detections.mask = segment(\n",
        "        sam_predictor=sam_predictor,\n",
        "        image=cv2.cvtColor(image, cv2.COLOR_BGR2RGB),\n",
        "        xyxy=detections.xyxy\n",
        "    )\n",
        "    images[image_name] = image\n",
        "    annotations[image_name] = detections"
      ],
      "metadata": {
        "id": "KbVv0nllR0Io"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ANNOTATIONS_DIRECTORY = os.path.join(HOME, 'annotations')\n",
        "\n",
        "MIN_IMAGE_AREA_PERCENTAGE = 0.002\n",
        "MAX_IMAGE_AREA_PERCENTAGE = 0.80\n",
        "APPROXIMATION_PERCENTAGE = 0.75"
      ],
      "metadata": {
        "id": "0VRl1j7yR342"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sv.Dataset(\n",
        "    classes=CLASSES,\n",
        "    images=images,\n",
        "    annotations=annotations\n",
        ").as_pascal_voc(\n",
        "    annotations_directory_path=ANNOTATIONS_DIRECTORY,\n",
        "    min_image_area_percentage=MIN_IMAGE_AREA_PERCENTAGE,\n",
        "    max_image_area_percentage=MAX_IMAGE_AREA_PERCENTAGE,\n",
        "    approximation_percentage=APPROXIMATION_PERCENTAGE\n",
        ")"
      ],
      "metadata": {
        "id": "OhYVdVyIR78g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT_NAME = \"auto-generated-dataset-7\"\n",
        "PROJECT_DESCRIPTION = \"auto-generated-dataset-7\""
      ],
      "metadata": {
        "id": "jkl7NVubR-zB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import roboflow\n",
        "from roboflow import Roboflow\n",
        "\n",
        "roboflow.login()\n",
        "\n",
        "workspace = Roboflow().workspace()\n",
        "new_project = workspace.create_project(\n",
        "    project_name=PROJECT_NAME,\n",
        "    project_license=\"MIT\",\n",
        "    project_type=\"instance-segmentation\",\n",
        "    annotation=PROJECT_DESCRIPTION)"
      ],
      "metadata": {
        "id": "1lL1R0H3SBpF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "for image_path in tqdm(image_paths):\n",
        "    image_name = image_path.name\n",
        "    annotation_name = f\"{image_path.stem}.xml\"\n",
        "    image_path = str(image_path)\n",
        "    annotation_path = os.path.join(ANNOTATIONS_DIRECTORY, annotation_name)\n",
        "    new_project.upload(\n",
        "        image_path=image_path,\n",
        "        annotation_path=annotation_path,\n",
        "        split=\"train\",\n",
        "        is_prediction=True,\n",
        "        overwrite=True,\n",
        "        tag_names=[\"auto-annotated-with-grounded-sam\"],\n",
        "        batch_name=\"auto-annotated-with-grounded-sam\"\n",
        "    )"
      ],
      "metadata": {
        "id": "zjf_C7SFSDq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {HOME}\n",
        "\n",
        "import roboflow\n",
        "from roboflow import Roboflow\n",
        "\n",
        "roboflow.login()\n",
        "\n",
        "rf = Roboflow()\n",
        "\n",
        "project = rf.workspace(\"wensuki-wxugk\").project(\"vehicle-accident-detection-jtx9t\")\n",
        "dataset = project.version(3).download(\"voc\")"
      ],
      "metadata": {
        "id": "ngUCY-lsSIJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.location"
      ],
      "metadata": {
        "id": "n8zLBAIlSJSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls {dataset.location}"
      ],
      "metadata": {
        "id": "xOUR6irNSMHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "object_detection_dataset = sv.Dataset.from_pascal_voc(\n",
        "    images_directory_path=f\"{dataset.location}/train\",\n",
        "    annotations_directory_path=f\"{dataset.location}/train\"\n",
        ")"
      ],
      "metadata": {
        "id": "mbvSh9nLSOIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "random.seed(9001)"
      ],
      "metadata": {
        "id": "tANQrYZzSQqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_names = list(object_detection_dataset.images.keys())\n",
        "image_name = random.choice(image_names)\n",
        "\n",
        "image = object_detection_dataset.images[image_name]\n",
        "detections = object_detection_dataset.annotations[image_name]\n",
        "\n",
        "box_annotator = sv.BoxAnnotator()\n",
        "\n",
        "annotated_image = box_annotator.annotate(scene=image.copy(), detections=detections, skip_label=True)\n",
        "\n",
        "%matplotlib inline\n",
        "sv.plot_image(annotated_image, (16, 16))"
      ],
      "metadata": {
        "id": "yqHxHzrBSSq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_names = list(object_detection_dataset.images.keys())\n",
        "image_name = random.choice(image_names)\n",
        "\n",
        "image = object_detection_dataset.images[image_name]\n",
        "detections = object_detection_dataset.annotations[image_name]\n",
        "\n",
        "box_annotator = sv.BoxAnnotator()\n",
        "\n",
        "annotated_image = box_annotator.annotate(scene=image.copy(), detections=detections, skip_label=True)\n",
        "\n",
        "%matplotlib inline\n",
        "sv.plot_image(annotated_image, (16, 16))"
      ],
      "metadata": {
        "id": "NraOg_wMSUvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.notebook import tqdm\n",
        "\n",
        "for image_name, image in tqdm(object_detection_dataset.images.items()):\n",
        "    detections = object_detection_dataset.annotations[image_name]\n",
        "    detections.mask = segment(\n",
        "        sam_predictor=sam_predictor,\n",
        "        image=cv2.cvtColor(image, cv2.COLOR_BGR2RGB),\n",
        "       xyxy=detections.xyxy\n",
        "    )"
      ],
      "metadata": {
        "id": "UIOGnjaOSXpq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ANNOTATIONS_DIRECTORY = os.path.join(dataset.location, 'annotations')\n",
        "\n",
        "MIN_IMAGE_AREA_PERCENTAGE = 0.002\n",
        "MAX_IMAGE_AREA_PERCENTAGE = 0.80\n",
        "APPROXIMATION_PERCENTAGE = 0.75"
      ],
      "metadata": {
        "id": "3GMvBTVTSbAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "object_detection_dataset.as_pascal_voc(\n",
        "    annotations_directory_path=ANNOTATIONS_DIRECTORY,\n",
        "    min_image_area_percentage=MIN_IMAGE_AREA_PERCENTAGE,\n",
        "    max_image_area_percentage=MAX_IMAGE_AREA_PERCENTAGE,\n",
        "    approximation_percentage=APPROXIMATION_PERCENTAGE\n",
        ")"
      ],
      "metadata": {
        "id": "WQhNYz_uSiZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import re  # To sanitize annotation name\n",
        "\n",
        "# Define a function to sanitize the annotation name\n",
        "def sanitize_annotation(annotation):\n",
        "    # Replace spaces and underscores with dashes, and remove other special characters\n",
        "    sanitized = re.sub(r'[^a-zA-Z0-9-]', '', annotation.replace(' ', '-').replace('_', '-'))\n",
        "    return sanitized[:255]  # Ensure it's less than 256 characters\n",
        "\n",
        "# Create a valid annotation name\n",
        "annotation_name = sanitize_annotation(f\"{dataset.name}-boxes-to-segmentations\")\n",
        "\n",
        "from roboflow import Roboflow\n",
        "\n",
        "roboflow.login()\n",
        "\n",
        "workspace = Roboflow().workspace()\n",
        "new_project = workspace.create_project(\n",
        "    project_name=dataset.name,\n",
        "    project_license=\"MIT\",\n",
        "    project_type=\"instance-segmentation\",\n",
        "    annotation=annotation_name  # Pass the sanitized annotation name\n",
        ")"
      ],
      "metadata": {
        "id": "3UATItgESkYz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "image_paths = sv.list_files_with_extensions(directory=f\"{dataset.location}/train\", extensions=[\"jpg\", \"jpeg\", \"png\"])\n",
        "for image_path in tqdm(image_paths):\n",
        "    image_name = image_path.name\n",
        "    annotation_name = f\"{image_path.stem}.xml\"\n",
        "    image_path = str(image_path)\n",
        "    annotation_path = os.path.join(ANNOTATIONS_DIRECTORY, annotation_name)\n",
        "    new_project.upload(\n",
        "        image_path=image_path,\n",
        "        annotation_path=annotation_path,\n",
        "        split=\"train\",\n",
        "        is_prediction=True,\n",
        "        overwrite=True,\n",
        "        tag_names=[\"auto-annotated-with-grounded-sam\"],\n",
        "        batch_name=\"auto-annotated-with-grounded-sam\"\n",
        "    )"
      ],
      "metadata": {
        "id": "Amsp7Al2So3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "image_paths = sv.list_files_with_extensions(directory=f\"{dataset.location}/train\", extensions=[\"jpg\", \"jpeg\", \"png\"])\n",
        "\n",
        "for image_path in tqdm(image_paths):\n",
        "    image_name = image_path.name\n",
        "    annotation_name = f\"{image_path.stem}.xml\"\n",
        "    image_path = str(image_path)\n",
        "    annotation_path = os.path.join(ANNOTATIONS_DIRECTORY, annotation_name)\n",
        "\n",
        "    try:\n",
        "\n",
        "        new_project.upload(\n",
        "            image_path=image_path,\n",
        "            annotation_path=annotation_path,\n",
        "            split=\"train\",\n",
        "            is_prediction=True,\n",
        "            overwrite=True,\n",
        "            tag_names=[\"auto-annotated-with-grounded-sam\"],\n",
        "            batch_name=\"auto-annotated-with-grounded-sam\"\n",
        "        )\n",
        "    except Exception as e:\n",
        "\n",
        "        if \"already annotated\" in str(e):\n",
        "            print(f\"Skipping {image_name}: Already annotated.\")\n",
        "            continue\n",
        "        else:\n",
        "            print(f\"Failed to upload {image_name}: {str(e)}\")\n",
        "            continue\n"
      ],
      "metadata": {
        "id": "g8fjpEExSrXb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}