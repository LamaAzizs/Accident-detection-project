import cv2
import streamlit as st
import pandas as pd
import os
import time
from ultralytics import YOLO
import numpy as np 
import google.generativeai as genai
from dotenv import load_dotenv
import random
from arabic_support import support_arabic_text

# Support Arabic text alignment in all components
support_arabic_text(all=True)
# Load the YOLO model
model = YOLO('runs/detect/train47/weights/best.pt')

# model = YOLO('bestyolo11.pt')
modelf = YOLO('injury.pt')

# model = YOLO('best(1).pt')

translation_dict = {
    'bike': 'Ø¯Ø±Ø§Ø¬Ø©',
    'car': 'Ø³ÙŠØ§Ø±Ø©',
    'injured': 'Ù…ØµØ§Ø¨',
    'vehicle': 'Ù…Ø±ÙƒØ¨Ø©'
}

# Ø¯Ø§Ù„Ø© Ù„ØªØ¹Ø±ÙŠØ¨ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„ØªØµÙ†ÙŠÙØ§Øª
def translate_class_name(class_name):
    # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø§Ø³Ù… ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ ÙƒÙ„Ù…Ø© "accident"ØŒ ÙŠÙØ­ÙˆÙ‘Ù„ Ø¥Ù„Ù‰ "Ø­Ø§Ø¯Ø«"
    if 'accident' in class_name.lower():
        return 'Ø­Ø§Ø¯Ø«'
    
    # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø§Ø³Ù… Ø§Ù„Ø£ØµÙ„ÙŠ Ø¥Ù„Ù‰ ÙƒÙ„Ù…Ø§Øª ÙˆØªØ±Ø¬Ù…Ø© ÙƒÙ„ ÙƒÙ„Ù…Ø©
    words = class_name.split()
    translated_words = [translation_dict.get(word.lower(), word) for word in words]
    translated_name = ' '.join(translated_words)
    return translated_name

# Create "reports" and "report_images" folders if they don't exist
if not os.path.exists('reports'):
    os.makedirs('reports')

if not os.path.exists('report_images'):
    os.makedirs('report_images')

# Initialize the session state for accident reports if it doesn't exist
if 'report_filenames' not in st.session_state:
    st.session_state.report_filenames = []

# Function to generate and save an accident report as CSV
def generate_report(class_name, image_filename, description=None):
    report_time = time.strftime("%Y-%m-%d_%H-%M-%S", time.localtime())  # Current time for filename
    report_filename = f"report_{report_time}.csv"
    report_path = os.path.join('reports', report_filename)

    # ØªØ¹Ø±ÙŠØ¨ Ø§Ø³Ù… Ø§Ù„ØªØµÙ†ÙŠÙ
    translated_class_name = translate_class_name(class_name)

    # Create a DataFrame for the report, including a Description column
    report_data = {
        'Class': translated_class_name,  # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø§Ø³Ù… Ø§Ù„Ù…Ø¹Ø±Ø¨ Ù‡Ù†Ø§
        'Time': report_time,
        'Description': description  # New Description field
    }
    
    report_df = pd.DataFrame([report_data])

    # Save the DataFrame to a CSV file
    report_df.to_csv(report_path, index=False)

    # Add the report filename and associated image filename to the session state
    st.session_state.report_filenames.append((report_filename, image_filename))
    return report_filename


# Function to generate an accident description based on the image
# def generate_accident_report(image_path, yolo_report=None, time=None):
#     # Set up the API key
#     load_dotenv()
#     api_key = os.getenv('GOOGLE_API_KEY')
#     genai.configure(api_key=api_key)

#     # Upload the image using the File API
#     uploaded_file = genai.upload_file(path=image_path[-1], display_name="Accident Scene")
#     st.write(yolo_report)
#     # Construct the prompt
#     prompt = "Describe the accident based on the given image. make proficinal report without mentioning what you are doing \
#         make percise and consise so the officer can make decision be very sure whene makegin this report don't mention \
#             that this report is based on the image or it may not be accurate "
#     if yolo_report:
#         prompt += f" this is the calsses names for yolo report: {yolo_report}. Provide more details about the scene."
#     if time:
#         prompt += f" This incident occurred at {time}."

#     # Add specific instructions for the model to make the report useful for 911.
#     prompt += (" Include details such as the type and number of vehicles involved and there types and colors, "
#                "visible damage, any hazards, road conditions, presence of people, "
#                "and any blocked traffic. Provide suggestions for emergency response actions."
#                "i need it very short not more then 5 lines"
#                "and use spsific template like car1:\n car2:\n short descriptoin:\n and so on add any nedded failds")

#     # Choose the model and generate the response
#     try:
#         model = genai.GenerativeModel(model_name="gemini-1.5-pro-exp-0827")
#         response = model.generate_content([uploaded_file, prompt])
#         return response.text
#     except Exception as e:
#         return f"Failed to generate report: {str(e)}"

def generate_accident_report(image_path, yolo_report=None, time=None):
    # Ø¥Ø¹Ø¯Ø§Ø¯ Ù…ÙØªØ§Ø­ API
    load_dotenv()
    api_key = os.getenv('GOOGLE_API_KEY')
    genai.configure(api_key=api_key)

    # Ø±ÙØ¹ Ø§Ù„ØµÙˆØ±Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… API
    uploaded_file = genai.upload_file(path=image_path[-1], display_name="ØµÙˆØ±Ø© Ø§Ù„Ø­Ø§Ø¯Ø«")

    # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø·Ù„Ø¨
    prompt = " Ù‚Ù… Ø¨ÙˆØµÙ Ø§Ù„Ø­Ø§Ø¯Ø« Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ù‚Ø¯Ù…Ø©. Ø§Ø¬Ø¹Ù„ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ø­ØªØ±Ø§ÙÙŠÙ‹Ø§  Ù…Ø¹ Ø¹Ø¯Ù…   Ø°ÙƒØ± Ø£Ù†Ù‡ ÙŠØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ø§Ù„ØµÙˆØ±Ø© Ø£ Ø£Ùˆ Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ© Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ Ø­Ø§Ø¯Ø« Ùˆ   . "
    prompt += "ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ù…Ù†Ø¸Ù…Ù‹Ø§ ÙˆÙŠØ³Ø§Ø¹Ø¯ Ø§Ù„Ù…Ø³Ø¤ÙˆÙ„ Ø¹Ù„Ù‰ Ø§ØªØ®Ø§Ø° Ø§Ù„Ù‚Ø±Ø§Ø± Ø¨Ø³Ø±Ø¹Ø©. "
    if yolo_report:
        prompt += f"Ù‡Ø°Ù‡ Ù‡ÙŠ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„ÙØ¦Ø§Øª ÙˆÙÙ‚Ù‹Ø§ Ù„ØªÙ‚Ø±ÙŠØ± YOLO: {yolo_report}. Ø£Ø¶Ù Ø§Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ø­ÙˆÙ„ Ø§Ù„Ù…Ø´Ù‡Ø¯. "
    if time:
        prompt += f"ÙˆÙ‚Ø¹ Ù‡Ø°Ø§ Ø§Ù„Ø­Ø§Ø¯Ø« ÙÙŠ Ø§Ù„Ø³Ø§Ø¹Ø© {time}. "

    # Ø¥Ø¶Ø§ÙØ© ØªØ¹Ù„ÙŠÙ…Ø§Øª Ù…Ø­Ø¯Ø¯Ø© Ù„Ø¬Ø¹Ù„ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ù…ÙÙŠØ¯Ù‹Ø§ Ù„Ù„Ø·ÙˆØ§Ø±Ø¦
    prompt += (
        "ÙŠØ¬Ø¨ Ø£Ù† ÙŠØªØ¶Ù…Ù† Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ø§Ù„ØªØ§Ù„ÙŠØ© Ø¨Ø´ÙƒÙ„ Ù…Ù†Ø¸Ù… ÙˆÙƒÙ„ Ø¹Ù†ÙˆØ§Ù† Ù…Ù† Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ† Ø§Ù„ØªØ§Ù„ÙŠØ©  ÙÙŠ Ø³Ø·Ø± Ù…Ù†ÙØµÙ„ : "
        "Ù†ÙˆØ¹ Ø§Ù„Ø­Ø§Ø¯Ø«:"
        "Ø§Ù„Ù…ÙƒØ§Ù†:"
        "Ø§Ù„Ù…Ø±ÙƒØ¨Ø§Øª:"
        " ÙˆØµÙ Ø§Ù„Ø­Ø§Ø¯Ø«:"
        "Ø§Ø­Ø°Ù Ø§Ù„Ø§Ø³Ø·Ø± Ø¨ÙŠÙ† Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ† ÙˆØ§Ø°ÙƒØ± Ø§Ù„Ø§Ø´ÙŠØ§Ø¡ Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ ÙˆØµÙ yolo Ù„Ø§ ØªØ¬Ø¹Ù„ Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ† ÙƒØ¨ÙŠØ±Ø© ÙˆÙ‚Ù„Ù„ Ø­Ø¬Ù… Ø§Ù„ØªÙ‚Ø±ÙŠØ±"
        " ÙˆÙ„Ø§ ÙŠÙˆØ¬Ø¯ Ø§Ø³Ø·Ø± ÙƒØ«ÙŠØ±, Ù„Ø§ ØªØªØ¬Ø§ÙˆØ² 8 Ø§Ø³Ø·Ø± Ù…Ø¹ ÙˆØ¶Ø¹ Ø§Ø³Ø·Ø± Ø¨Ø¹Ø¯ ÙƒÙ„ ÙÙ‚Ø±Ø© Ø¨Ø­ÙŠØ« ØªÙƒÙˆÙ† ÙˆÙŠÙƒÙˆÙ† Ø§Ù„ÙˆÙ‚Øª Ù…Ø¹ ÙˆØµÙ Ø§Ù„Ø­Ø§Ø¯Ø« Ù„Ø§ØªØ¶Ø¹ ÙƒÙ„ Ø¹Ù†ÙˆØ§Ù† Ø¨Ø§Ù„Ø®Ø· Ø§Ù„Ø¹Ø±ÙŠØ¶ "         
        )

    # Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø±Ø¯
    try:
        model = genai.GenerativeModel(model_name="gemini-1.5-pro-exp-0827")
        response = model.generate_content([uploaded_file, prompt])
        return response.text
    except Exception as e:
        return f"ÙØ´Ù„ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªÙ‚Ø±ÙŠØ±: {str(e)}"




def display_annotated_video(video_path):
    cap = cv2.VideoCapture(video_path)

    # Check if the video capture object is opened successfully
    if not cap.isOpened():
        st.error("Error: Could not open video.")
        return

    # Create a placeholder for the video frames
    frame_placeholder = st.empty()
    class_names = set()
    accident_detected = False
    list_of_images = []

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        height, width = frame.shape[:2]
        new_width = 1080
        new_height = int(height * (new_width / width))
        frame_small = cv2.resize(frame, (new_width, new_height))
        # Annotate frame
        results = model.predict(source=frame_small, conf=0.6, device= 0,imgsz= 640)
       
        
        annotated_frame = results[0].plot()
        boxes_results = results[0].boxes
        boxes_resultsf = None
        
        if True:
            resultsf = modelf.predict(source=annotated_frame, conf=0.72, device= 0,imgsz= 640)
            annotated_frame = resultsf[0].plot() 
            boxes_resultsf = resultsf[0].boxes
            frame_rgb = cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB)
            frame_placeholder.image(frame_rgb, channels="RGB")
        else:
            frame_rgb = cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB)
            frame_placeholder.image(frame_rgb, channels="RGB")
        
        if boxes_resultsf:
            for box in boxes_resultsf:
                class_id = int(box.cls[0])  # Class ID of the detected object
                class_name = modelf.names[class_id]
                translated_class_name = translate_class_name(class_name)
                if translated_class_name not in class_names:
                    st.info(f' ØªÙ… Ø§ÙƒØªØ´Ø§Ù {translated_class_name}', icon="â„¹ï¸")
                    class_names.add(translated_class_name)

        for box in boxes_results:
            class_id = int(box.cls[0])  # Class ID of the detected object
            class_name = model.names[class_id]
            translated_class_name = translate_class_name(class_name)
            if translated_class_name not in class_names:
                st.info(f' ØªÙ… Ø§ÙƒØªØ´Ø§Ù {translated_class_name}', icon="â„¹ï¸")
                class_names.add(translated_class_name)

            # Check if it's an accident in the current segment
            if "Ø­Ø§Ø¯Ø«" in translated_class_name:
                image_filename = f"image_{time.strftime('%Y-%m-%d_%H-%M-%S')}.jpg"
                image_path = os.path.join('report_images', image_filename)
                cv2.imwrite(image_path, frame)  # Save the image
                list_of_images.append(image_path)
                accident_detected = True

        

           

    if accident_detected:
        report_filename = generate_report(' '.join(class_names), list_of_images)
        st.toast(f"ØªÙ… Ø§ÙƒØªØ´Ø§Ù Ø­Ø§Ø¯Ø«: {' '.join(class_names)}. ØªÙ… Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø±ÙŠØ±: {report_filename}", icon="ğŸš¨")

    cap.release()
    st.write("Ø§ÙƒØªÙ…Ù„ ØªØ´ØºÙŠÙ„ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ.")

# Function to show reports
# Function to show reports
# Function to show reports
def show_reports():
    st.title("ØªÙ‚Ø§Ø±ÙŠØ± Ø§Ù„Ø­ÙˆØ§Ø¯Ø«")

    if st.session_state.report_filenames:
        for report_filename, image_paths in st.session_state.report_filenames:
            report_path = os.path.join('reports', report_filename)
            report_df = pd.read_csv(report_path)

            # Ø¹Ø±Ø¶ Ø¹Ù†ÙˆØ§Ù† Ø§Ù„ØªÙ‚Ø±ÙŠØ±
            st.subheader(f"ØªÙ‚Ø±ÙŠØ± Ø­ÙˆÙ„  ({','.join(report_df['Class'][0].split(' '))}) ÙÙŠ {str(report_df['Time'][0])}")

            # Ø¹Ø±Ø¶ ØªÙØ§ØµÙŠÙ„ Ø§Ù„ØªÙ‚Ø±ÙŠØ±
            with st.expander("ØªÙØ§ØµÙŠÙ„ Ø§Ù„ØªÙ‚Ø±ÙŠØ±"):
                num_images_to_show = min(2, len(image_paths))
                selected_images = image_paths[0], image_paths[-1]

                # Ø¹Ø±Ø¶ Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…Ø®ØªØ§Ø±Ø© Ø¬Ù†Ø¨Ù‹Ø§ Ø¥Ù„Ù‰ Ø¬Ù†Ø¨
                cols = st.columns(num_images_to_show)
                for i in range(num_images_to_show):
                    cols[i].image(selected_images[i], use_column_width=True)

                # ØªÙˆÙ„ÙŠØ¯ ÙˆØµÙ Ù„Ù„ØªÙ‚Ø±ÙŠØ± Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ù‹Ø§
                description_key = f"description_{report_filename}"
                if 'Description' in report_df.columns and pd.notnull(report_df['Description'][0]):
                    st.write("Ø§Ù„ÙˆØµÙ: \n", report_df['Description'][0])
                else:
                    if description_key not in st.session_state:
                        st.session_state[description_key] = ""
                    if st.button(f"ØªÙˆÙ„ÙŠØ¯ ÙˆØµÙ Ù„Ù€ {report_df['Class'][0]}_{str(report_df['Time'][0])}"):
                        description = generate_accident_report(selected_images, f"{report_df['Class'][0]}", report_df["Time"][0])
                        st.session_state[description_key] = description
                        report_df['Description'] = description
                        report_df.to_csv(report_path, index=False)
                        st.success("ØªÙ… ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ÙˆØµÙ Ø¨Ù†Ø¬Ø§Ø­!")

                    if st.session_state[description_key]:
                        st.write(st.session_state[description_key])
    else:
        st.write("Ù„Ø§ ØªÙˆØ¬Ø¯ ØªÙ‚Ø§Ø±ÙŠØ± Ø­ÙˆØ§Ø¯Ø« Ø­ØªÙ‰ Ø§Ù„Ø¢Ù†.")





# Streamlit app UI
st.sidebar.title("Ø§Ù„ÙˆØ§Ø¬Ù‡Ø§Øª")
page = st.sidebar.radio("Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø§Ø®ØªÙŠØ§Ø±:", ["Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø­ÙˆØ§Ø¯Ø« Ù…Ù† Ù…Ù‚Ø§Ø·Ø¹ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ", "Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ±"])


if page == "Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø­ÙˆØ§Ø¯Ø« Ù…Ù† Ù…Ù‚Ø§Ø·Ø¹ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ":
    st.title("Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø­ÙˆØ§Ø¯Ø« Ù…Ù† ÙƒØ§Ù…ÙŠØ±Ø§Øª Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø©")
    uploaded_video = st.file_uploader("Ø§Ø±ÙØ¹ ÙÙŠØ¯ÙŠÙˆ", type=["mp4", "avi", "mov", "gif"])

    if uploaded_video is not None:
        # Save uploaded video to a temporary file
        video_path = os.path.join('temp', 'uploaded_video.mp4')
        with open(video_path, 'wb') as f:
            f.write(uploaded_video.read())

        # Display the annotated video using the placeholder
        display_annotated_video(video_path)


elif page == "Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ±":
    show_reports()
